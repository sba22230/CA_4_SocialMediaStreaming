{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cef3a63",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis for the word rugby\n",
    "\n",
    "Connect Spark to Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df04beb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars \"/usr/local/spark/jars/mongo-spark-connector_2.12-3.0.2.jar,/usr/local/spark/jars/mongo-java-driver-3.12.9.jar\" pyspark-shell'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c12edd37",
   "metadata": {},
   "source": [
    "Note the inferschema is set to false, this makes spark read the entire database and not infer the values of fields from the first set of fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84472e36",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# fix read bug, basically turn off sampling\n",
    "spark = SparkSession.builder.appName(\"TwitterMongo\") \\\n",
    ".config(\"spark.mongodb.input.database\", \"mongodb://localhost:27017/twitter\") \\\n",
    ".config(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/twitter.tweets\") \\\n",
    ".config(\"spark.mongodb.read.sql.inferSchema.mapTypes.enabled\", \"FALSE\") \\\n",
    ".config(\"spark.mongodb.output.uri\",\"mongodb://localhost:27017/twitter.tweets\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4badca7e",
   "metadata": {},
   "source": [
    "### Create the Session\n",
    "\n",
    "And load all of the Twitter data in MongoDB\n",
    "\n",
    "Print out the twitter tweet schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e3c9a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".master(\"local\") \\\n",
    ".appName(\"ABC\") \\\n",
    ".config(\"spark.driver.memory\", \"15g\") \\\n",
    ".config(\"spark.mongodb.read.connection.uri\", \"mongodb://localhost:27017/twitter\") \\\n",
    ".config(\"spark.mongodb.write.connection.uri\", \"mongodb://localhost:27017/twitter\") \\\n",
    ".config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector:2.12-3.0.2') \\\n",
    ".getOrCreate()\n",
    "# read data from mongodb collection \"questions\" into a dataframe \"df\"\n",
    "df = spark.read \\\n",
    ".format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    ".option(\"uri\", \"mongodb://localhost:27017/twitter\") \\\n",
    ".option(\"database\", \"twitter\") \\\n",
    ".option(\"collection\", \"tweets\") \\\n",
    ".load()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b68eb5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "404e0b94",
   "metadata": {},
   "source": [
    "Create a spark object of the tweets held in the mongo db \n",
    "\n",
    "It is easier to use SQL statements and Pyspark to clean the data rather than writing queries in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330eb426",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tweets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ffce3ac",
   "metadata": {},
   "source": [
    "How many tweets in the DB all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba51bf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT DISTINCT id FROM tweets\")\n",
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55a62139",
   "metadata": {},
   "source": [
    "How many tweets by language \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9015ec",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#pip install plotly\n",
    "import pyspark.pandas as ps\n",
    "import plotly\n",
    "dfLang = spark.sql(\"SELECT DISTINCT lang, CAST(count(id) AS INT) as TweetCount FROM tweets GROUP BY lang \\\n",
    "                   ORDER BY TweetCount DESC LIMIT 10\")\n",
    "dfLang.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9e016",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tempdf = ps.DataFrame(dfLang)\n",
    "\n",
    "tempdf.plot(kind='bar', x='lang', y='TweetCount')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bc9f4f8",
   "metadata": {},
   "source": [
    "How many tweets by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c7c69",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfLoc = spark.sql(\"SELECT DISTINCT user.location AS Location, CAST(count(id) AS INT) as TweetCount FROM tweets GROUP BY user.location \\\n",
    "                   ORDER BY TweetCount DESC LIMIT 10\")\n",
    "dfLoc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b94c58",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tempdf = ps.DataFrame(dfLoc)\n",
    "\n",
    "tempdf.plot(kind='bar', x='Location', y='TweetCount')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "106f0306",
   "metadata": {},
   "source": [
    "Now limit the dataset to English texts and tweets with the rugby in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41824ab2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfEnTwt = spark.sql(\"SELECT * FROM tweets WHERE lang = 'en' AND text LIKE '%rugby%'\")\n",
    "dfEnTwt.createOrReplaceTempView(\"en_tweets\")\n",
    "dfEnTwt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5654e5c3",
   "metadata": {},
   "source": [
    "Now how many tweets in the English language dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37eb383",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfEnTwt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9182c74",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfLoc = spark.sql(\"SELECT DISTINCT user.location AS Location, CAST(count(id) AS INT) as TweetCount FROM en_tweets GROUP BY user.location \\\n",
    "                   ORDER BY TweetCount DESC LIMIT 10\")\n",
    "dfLoc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c186b0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# select tweet id, geo, lang, quoted_status,quoted_status.geo \n",
    "# Having a look at some the data\n",
    "dfOne = spark.sql(\"SELECT DISTINCT id,  text, quote_count, reply_count, retweet_count, favorite_count, geo, place, lang, \\\n",
    "                  quoted_status,quoted_status.geo, quoted_status.text, user.name, user.location   \\\n",
    "                  FROM en_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf79faf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dfDay= spark.sql(\"SELECT DISTINCT CAST(substring(created_at, 27, 4) AS INT) as Year, \\\n",
    "          CAST(from_unixtime(unix_timestamp(substring(created_at, 5, 3), 'MMM'), 'MM') As INT) as Month, \\\n",
    "          CAST(substring(created_at, 9, 2) AS INT) as Day, \\\n",
    "          CAST(count(id) AS INT) as TweetCount \\\n",
    "          FROM en_tweets \\\n",
    "          WHERE lang = 'en' AND text LIKE '%rugby%' GROUP BY substring(created_at, 27, 4), \\\n",
    "          substring(created_at, 5, 3), \\\n",
    "          substring(created_at, 9, 2)\")\n",
    "\n",
    "dfDay.createOrReplaceTempView(\"tweetsByDay\")\n",
    "\n",
    "dfDay = spark.sql(\"SELECT CONCAT(Year, '_', Month, '_', DAY) AS Date, TweetCount  FROM tweetsByDay ORDER BY Year, Month, Day\")\n",
    "\n",
    "dfDay.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccb373",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tempdf = ps.DataFrame(dfDay)\n",
    "\n",
    "tempdf.plot(kind='bar', x='Date', y='TweetCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c0e4d4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfWeek = spark.sql(\"SELECT Year, weekofyear(make_date(Year, Month, Day)) as wkofYr , SUM(TweetCount) as TweetCountbyWeek \\\n",
    "                   FROM tweetsByDay \\\n",
    "                   GROUP BY Year, weekofyear(make_date(Year, Month, Day))\")\n",
    "\n",
    "dfWeek.createOrReplaceTempView(\"tweetsByWeek\")\n",
    "dfWeek = spark.sql(\"SELECT Year, wkofYr, CONCAT(Year, '_', wkofYr) AS yr_wk, TweetCountbyWeek  FROM tweetsByWeek ORDER BY Year, wkofYr\")\n",
    "dfWeek.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a883c3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tempdf = ps.DataFrame(dfWeek)\n",
    "\n",
    "tempdf.plot(kind='bar', x='yr_wk', y='TweetCountbyWeek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673fae3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get the tweet count by month\n",
    "dfMonth = spark.sql(\"SELECT Year, Month, SUM(TweetCount) as TweetCountbyMonth \\\n",
    "                     FROM tweetsByDay GROUP BY Year, Month\")\n",
    "dfMonth.createOrReplaceTempView(\"tweetsByMonth\")\n",
    "dfMonth = spark.sql(\"SELECT Year, Month, CONCAT(Year, '_', Month) AS MonthYr, TweetCountbyMonth  FROM tweetsByMonth ORDER BY Year, Month \")\n",
    "dfMonth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280681b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tempdf = ps.DataFrame(dfMonth)\n",
    "\n",
    "tempdf.plot(kind='bar', x='MonthYr', y='TweetCountbyMonth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c854ddd",
   "metadata": {},
   "source": [
    "### Next up is text clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232fafd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install wordcloud\n",
    "#%pip install vadersentiment\n",
    "## sentiment analysis ref: https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/?ref=lbp\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# function to print sentiments\n",
    "# of the sentence.\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "     \n",
    "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "    #print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "    #print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "    #print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    " \n",
    "    #print(\"Sentence Overall Rated As\", end = \" \")\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        print(\"Positive\")\n",
    " \n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "       print(\"Negative\")\n",
    " \n",
    "    else :\n",
    "        print(\"Neutral\")\n",
    "    \n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46273e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfText = spark.sql(\"SELECT DISTINCT id, text AS text FROM en_tweets\")\n",
    "dfText.createOrReplaceTempView(\"text\")\n",
    "dfText.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e65d385",
   "metadata": {},
   "source": [
    "Count the number of words in the tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fdd30a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "# heavy reliance on SQL functions in the following code\n",
    "\n",
    "dfWord = dfText.withColumn(\"Word\", explode(split(col(\"text\"), ' '))).groupBy(\"Word\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "dfWord.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a213b15",
   "metadata": {},
   "source": [
    "Count the number of characters including spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d5e4a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfChar = spark.sql(\"SELECT text, LENGTH(text) AS char FROM text ORDER BY char DESC\")\n",
    "dfChar.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24d9bf93",
   "metadata": {},
   "source": [
    "Check for special characters i.e. Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d58adb",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfSpecChar = spark.sql(\"SELECT text, regexp_extract_all(text, '(#\\\\\\\\w+)', 1) AS Hashtags FROM text WHERE text like '%#%' \")\n",
    "dfSpecChar.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e59219aa",
   "metadata": {},
   "source": [
    "Check for upper case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f54f8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfUpper = spark.sql(\"SELECT text FROM text WHERE translate(text, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', '') = ''\")\n",
    "dfUpper.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd4fcee0",
   "metadata": {},
   "source": [
    "Check for numbers \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0800f96",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfNum = spark.sql(\"SELECT text FROM text WHERE translate(text, '0123456789', '') <> text\")\n",
    "dfNum.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36f71ccd",
   "metadata": {},
   "source": [
    "This check does not really advance our understanding of the data, a lot of twitter names have numbers in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be29cf6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfNum.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1388760",
   "metadata": {},
   "source": [
    "Leave only text in the strings, all non alpha numeric characters are removed with the application of the regular expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f71dcc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pattern = r'[^a-zA-Z0-9\\s]'\n",
    "\n",
    "dfText = spark.sql(\"SELECT id, text AS orignialText, text FROM text\")\n",
    "dfText = dfText.withColumn(\"text\", regexp_replace('text', pattern, ''))\n",
    "dfText.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495e67e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfText.createOrReplaceTempView(\"text\") # this is cleaned txt\n",
    "dfText = spark.sql(\"SELECT id, orignialText, LOWER(TRIM(text)) AS text FROM text\")\n",
    "\n",
    "dfText.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5673de1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#now build a word cloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "dfText.createOrReplaceTempView(\"text\") # this is the trimmed txt\n",
    "dfText = spark.sql(\"SELECT id, orignialText, text FROM text\")\n",
    "dfText.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e99875b0",
   "metadata": {},
   "source": [
    "Fix the spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b93c2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "dfText = spark.sql(\"SELECT id, orignialText, text FROM text\")\n",
    "#dfText = dfText.withColumn(\"newtext\", col(TextBlob(\"text\").correct()))\n",
    "\n",
    "dfText.show(5)\n",
    "dfText.createOrReplaceTempView(\"text\") # this is the preprocessed SQL Style txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68d3a6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dfText = spark.sql(\"SELECT * FROM text\")\n",
    "\n",
    "dfText.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cfa2907",
   "metadata": {},
   "source": [
    "### Tokenize and Stem the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9baf1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60c90c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# stackoverflow ref: https://stackoverflow.com/questions/53579444\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bd404",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "dfTextTok = tokenizer.transform(dfText).select(\"text\",\"tokens\")\n",
    "dfText = dfText.join(dfTextTok, on=['text'], how='left_outer')\n",
    "dfText.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c3062",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "dfText = remover.transform(dfText).select(\"text\",\"tokens\",\"filtered\")\n",
    "dfText.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "734132fd",
   "metadata": {},
   "source": [
    "Now recheck for the most common words and decide if they need to be removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb3c3a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#dfWord = dfText.withColumn(\"Word\", explode(split(col(\"filtered\"), ' '))).groupBy(\"Word\").count().orderBy(desc(\"count\").limit(10))\n",
    "\n",
    "#dfWord.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "911b9595",
   "metadata": {},
   "source": [
    "Now look at rare words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec13397",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#dfWord = dfText.withColumn(\"Word\", explode(split(col(\"text\"), ' '))).groupBy(\"Word\").count().orderBy(asc(\"count\").limit(10))\n",
    "\n",
    "#dfWord.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8fcdc7c",
   "metadata": {},
   "source": [
    "Decided to stem the words as per this page https://stackoverflow.com/questions/53579444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a892b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# stem the words\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "dfText = dfText.withColumn(\"filtered_stemmed\", stemmer_udf(\"filtered\"))\n",
    "dfText.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0bc94",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out short words\n",
    "filterShortWords = udf(lambda row: [x for x in row if len(x) >= 4], ArrayType(StringType()))\n",
    "dfText = dfText.withColumn(\"filtered_stemmed\", filterShortWords(\"filtered_stemmed\"))\n",
    "\n",
    "dfText.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae79004",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfText.count()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f08f06d",
   "metadata": {},
   "source": [
    "### Advanced Text processing\n",
    "\n",
    "N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abccf034",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "547023fd",
   "metadata": {},
   "source": [
    "Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a1e03",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb942367",
   "metadata": {},
   "source": [
    "Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24b4e7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bb9068b",
   "metadata": {},
   "source": [
    "## Building the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd109f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0f73a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cfdafc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
